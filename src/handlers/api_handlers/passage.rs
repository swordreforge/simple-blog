use actix_web::{web, HttpResponse, HttpRequest, HttpMessage};
use serde::{Deserialize, Serialize};
use crate::db::repositories::{PassageRepository, AttachmentRepository, Repository};
use crate::db::models::Passage;
use crate::view_batch::{ViewBatchProcessor, ViewRecord, is_local_ip};
use std::sync::Arc;
use chrono::Utc;

/// æ–‡ç« å“åº”
#[derive(Debug, Serialize)]
pub struct PassageResponse {
    pub id: i64,
    pub uuid: String,  // Flake UUID
    pub title: String,
    pub content: String,  // åŸå§‹ Markdown å†…å®¹
    pub html_content: Option<String>,  // æ¸²æŸ“åçš„ HTML å†…å®¹
    pub summary: Option<String>,
    pub author: String,
    pub tags: String,
    pub category: String,
    pub status: String,
    pub file_path: Option<String>,
    pub visibility: String,
    pub is_scheduled: bool,
    pub published_at: Option<String>,
    pub cover_image: Option<String>,  // å°é¢å›¾ç‰‡è·¯å¾„
    pub created_at: String,
    pub updated_at: String,
}

/// åˆ›å»ºæ–‡ç« è¯·æ±‚
#[derive(Debug, Deserialize)]
pub struct CreatePassageRequest {
    pub title: String,
    pub content: String,
    pub summary: Option<String>,
    pub author: Option<String>,
    pub tags: Option<String>,
    pub category: Option<String>,
    pub status: Option<String>,
    pub file_path: Option<String>,
    pub visibility: Option<String>,
    pub is_scheduled: Option<bool>,
    pub published_at: Option<String>,
    pub cover_image: Option<String>,  // å°é¢å›¾ç‰‡è·¯å¾„
    pub created_at: Option<String>,  // åˆ›å»ºæ—¶é—´ï¼ˆå¯é€‰ï¼Œç”¨äºä¸Šä¼ è€æ–‡ä»¶æ—¶æŒ‡å®šï¼‰
}

/// æ›´æ–°æ–‡ç« è¯·æ±‚
#[derive(Debug, Deserialize)]
pub struct UpdatePassageRequest {
    pub title: Option<String>,
    pub content: Option<String>,
    pub original_content: Option<String>,
    pub summary: Option<String>,
    pub author: Option<String>,
    pub tags: Option<String>,
    pub category: Option<String>,
    pub status: Option<String>,
    pub file_path: Option<String>,
    pub visibility: Option<String>,
    pub is_scheduled: Option<bool>,
    pub published_at: Option<String>,
    pub cover_image: Option<String>,  // å°é¢å›¾ç‰‡è·¯å¾„
}

/// è·å–æ–‡ç« åˆ—è¡¨ï¼ˆå…¬å¼€ï¼‰
pub async fn list(
    repo: web::Data<Arc<dyn Repository>>,
    query: web::Query<std::collections::HashMap<String, String>>,
) -> HttpResponse {
    let passage_repo = PassageRepository::new(repo.get_pool().clone());
    
    // è§£æåˆ†é¡µå‚æ•°
    let limit: i64 = query.get("limit").and_then(|l| l.parse().ok()).unwrap_or(10);
    let page: i64 = query.get("page").and_then(|p| p.parse().ok()).unwrap_or(1);
    let offset = (page - 1) * limit;
    
    // è·å–å·²å‘å¸ƒçš„æ–‡ç« ï¼ˆä¸åŒ…å«å®Œæ•´å†…å®¹ï¼Œåªè¿”å›æ‘˜è¦ï¼‰
    match passage_repo.get_published(limit, offset).await {
        Ok(passages) => {
            // è·å–æ€»æ•°
            let total = match passage_repo.count_published().await {
                Ok(c) => c,
                Err(_) => passages.len() as i64,
            };
            
            let data: Vec<PassageResponse> = passages.into_iter()
                .map(|p| PassageResponse {
                    id: p.id.unwrap_or(0),
                    uuid: p.uuid.unwrap_or_default(),
                    title: p.title,
                    content: p.original_content.unwrap_or_default(), // è¿”å›åŸå§‹ Markdown å†…å®¹
                    html_content: None, // åˆ—è¡¨ä¸è¿”å› HTML å†…å®¹
                    summary: p.summary,
                    author: p.author,
                    tags: p.tags,
                    category: p.category,
                    status: p.status,
                    file_path: p.file_path,
                    visibility: p.visibility,
                    is_scheduled: p.is_scheduled,
                    published_at: p.published_at.map(|d| d.format("%Y-%m-%d %H:%M:%S").to_string()),
                    cover_image: p.cover_image,
                    created_at: p.created_at.format("%Y-%m-%d %H:%M:%S").to_string(),
                    updated_at: p.updated_at.format("%Y-%m-%d %H:%M:%S").to_string(),
                })
                .collect();
            
            let total_pages = (total + limit - 1) / limit;

            HttpResponse::Ok()
                .insert_header(("Cache-Control", "public, max-age=60")) // å…¬å¼€åˆ—è¡¨ç¼“å­˜ 1 åˆ†é’Ÿ
                .json(serde_json::json!({
                    "success": true,
                    "data": data,
                    "pagination": {
                        "page": page,
                        "limit": limit,
                        "total": total,
                        "total_pages": total_pages,
                        "has_more": page < total_pages
                    }
                }))
        }
        Err(e) => {
            eprintln!("è·å–æ–‡ç« åˆ—è¡¨å¤±è´¥: {}", e);
            HttpResponse::InternalServerError().json(serde_json::json!({
                "success": false,
                "message": "è·å–æ–‡ç« åˆ—è¡¨å¤±è´¥"
            }))
        }
    }
}

/// è·å–å•ç¯‡æ–‡ç« 
pub async fn get(
    repo: web::Data<Arc<dyn Repository>>,
    path: web::Path<String>,
    req: HttpRequest,
    view_batch_processor: web::Data<Arc<ViewBatchProcessor>>,
) -> HttpResponse {
    let param = path.into_inner();
    let passage_repo = PassageRepository::new(repo.get_pool().clone());
    
    // è·å–ç”¨æˆ·è§’è‰²
    let role: String = req.extensions().get::<crate::middleware::auth::RoleKey>()
        .map(|r| r.0.clone())
        .unwrap_or_else(|| String::new());
    
    // æ™ºèƒ½è¯†åˆ«ï¼šå¦‚æœæ˜¯çº¯æ•°å­—ï¼Œåˆ™æŒ‰ ID æŸ¥è¯¢ï¼›å¦åˆ™æŒ‰ UUID æŸ¥è¯¢
    let passage = if let Ok(id) = param.parse::<i64>() {
        // æ•°å­— ID æŸ¥è¯¢
        match passage_repo.get_by_id(id).await {
            Ok(p) => p,
            Err(e) => {
                eprintln!("è·å–æ–‡ç« å¤±è´¥: {}", e);
                return HttpResponse::NotFound().json(serde_json::json!({
                    "success": false,
                    "message": "æ–‡ç« ä¸å­˜åœ¨"
                }));
            }
        }
    } else {
        // UUID æŸ¥è¯¢
        match passage_repo.get_by_uuid(&param).await {
            Ok(p) => p,
            Err(e) => {
                eprintln!("è·å–æ–‡ç« å¤±è´¥: {}", e);
                return HttpResponse::NotFound().json(serde_json::json!({
                    "success": false,
                    "message": "æ–‡ç« ä¸å­˜åœ¨"
                }));
            }
        }
    };
    
    // æ£€æŸ¥æ–‡ç« çŠ¶æ€å’Œå¯è§æ€§
    if passage.status != "published" {
        if role != "admin" {
            return HttpResponse::Ok().json(serde_json::json!({
                "success": false,
                "message": "æ–‡ç« æœªå‘å¸ƒ",
                "status": passage.status
            }));
        }
    }
    
    if passage.visibility != "public" {
        if role != "admin" {
            return HttpResponse::Ok().json(serde_json::json!({
                "success": false,
                "message": "æ–‡ç« ä¸å¯è§",
                "visibility": passage.visibility
            }));
        }
    }
    
    if passage.is_scheduled {
        if let Some(published_at) = passage.published_at {
            if published_at > Utc::now() && role != "admin" {
                return HttpResponse::Ok().json(serde_json::json!({
                    "success": false,
                    "message": "æ–‡ç« å°šæœªå‘å¸ƒ",
                    "is_scheduled": true,
                    "published_at": published_at.format("%Y-%m-%d %H:%M:%S").to_string()
                }));
            }
        }
    }
    
    // ä½¿ç”¨æ‰¹é‡å¤„ç†å™¨è®°å½•æ–‡ç« é˜…è¯»ï¼ˆä¸é˜»å¡å“åº”ï¼‰
    let passage_uuid = passage.uuid.clone().unwrap_or_default();
    let user_agent = req.headers().get("user-agent")
        .and_then(|h| h.to_str().ok())
        .unwrap_or("unknown")
        .to_string();
    
    // è·å–å®¢æˆ·ç«¯IPï¼ˆç®€åŒ–ç‰ˆï¼‰
    let ip = "127.0.0.1".to_string(); // TODO: ä»è¯·æ±‚ä¸­è·å–çœŸå®IP

    // è¿‡æ»¤æœ¬åœ°IPï¼Œä¸è®°å½•
    if !is_local_ip(&ip) {
        // ä½¿ç”¨ GeoIP è·å–åœ°ç†ä½ç½®ä¿¡æ¯
        let geo_location = crate::geoip::lookup_ip(&ip);
        let country = geo_location.country;
        let city = geo_location.city;
        let region = geo_location.region;

        // ä½¿ç”¨æ‰¹é‡å¤„ç†å™¨å‘é€é˜…è¯»è®°å½•
        let view_record = ViewRecord {
            passage_uuid: passage_uuid.clone(),
            ip: ip.clone(),
            user_agent: Some(user_agent.clone()),
            country,
            city,
            region,
            view_time: Utc::now(),
        };

        if let Err(e) = view_batch_processor.record_view(view_record) {
            eprintln!("å‘é€é˜…è¯»è®°å½•åˆ°æ‰¹é‡å¤„ç†å™¨å¤±è´¥: {}", e);
        }
    }
    
    let response = PassageResponse {
        id: passage.id.unwrap_or(0),
        uuid: passage.uuid.unwrap_or_default(),
        title: passage.title,
        content: passage.original_content.unwrap_or_default(), // è¿”å›åŸå§‹ Markdown å†…å®¹
        html_content: Some(passage.content), // è¿”å›æ¸²æŸ“åçš„ HTML
        summary: passage.summary,
        author: passage.author,
        tags: passage.tags,
        category: passage.category,
        status: passage.status,
        file_path: passage.file_path,
        visibility: passage.visibility,
        is_scheduled: passage.is_scheduled,
        published_at: passage.published_at.map(|d| d.format("%Y-%m-%d %H:%M:%S").to_string()),
        cover_image: passage.cover_image,
        created_at: passage.created_at.format("%Y-%m-%d %H:%M:%S").to_string(),
        updated_at: passage.updated_at.format("%Y-%m-%d %H:%M:%S").to_string(),
    };
    
    // ç”Ÿæˆ ETag
    use md5::{Md5, Digest};
    let etag_data = format!("{}:{}", response.id, response.updated_at);
    let etag = format!("\"{:x}\"", Md5::digest(etag_data.as_bytes()));
    
    // æ£€æŸ¥ If-None-Match
    if let Some(if_none_match) = req.headers().get("if-none-match") {
        if let Ok(if_none_match_str) = if_none_match.to_str() {
            if if_none_match_str == etag {
                return HttpResponse::NotModified()
                    .insert_header(("ETag", etag))
                    .finish();
            }
        }
    }
    
    HttpResponse::Ok()
        .insert_header(("ETag", etag))
        .insert_header(("Cache-Control", "public, max-age=300")) // æ–‡ç« ç¼“å­˜ 5 åˆ†é’Ÿ
        .json(serde_json::json!({
            "success": true,
            "data": response
        }))
}

/// åˆ›å»ºæ–‡ç« 
pub async fn create(
    repo: web::Data<Arc<dyn Repository>>,
    req: web::Json<CreatePassageRequest>,
) -> HttpResponse {
    let passage_repo = PassageRepository::new(repo.get_pool().clone());
    
    // è½¬æ¢ Markdown ä¸º HTML
    let html_content = convert_markdown_to_html(&req.content);

    // å¤„ç†åˆ†ç±»ï¼Œç¡®ä¿åˆ†ç±»å­˜åœ¨
    let category_name = req.category.as_deref().unwrap_or("æœªåˆ†ç±»");
    let _ = ensure_category_exist(category_name).await;

    // å¤„ç†æ ‡ç­¾
    let tags_json = if let Some(ref tags) = req.tags {
        // è§£ææ ‡ç­¾ JSON å¹¶ç¡®ä¿æ ‡ç­¾å­˜åœ¨äº tags è¡¨ä¸­
        if let Ok(tag_list) = serde_json::from_str::<Vec<String>>(tags) {
            let _ = ensure_tags_exist(&tag_list).await;
            tags.clone()
        } else {
            "[]".to_string()
        }
    } else {
        "[]".to_string()
    };
    
    let now = Utc::now();
    
    // å¦‚æœæ²¡æœ‰æä¾› file_pathï¼Œåˆ™è‡ªåŠ¨ç”Ÿæˆ
    let file_path = if let Some(ref path) = req.file_path {
        path.clone()
    } else {
        // è‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶è·¯å¾„ï¼šmarkdown/YYYY/MM/DD/title.md
        let date = now.format("%Y/%m/%d").to_string();
        let safe_title = req.title.chars()
            .map(|c| if c.is_alphanumeric() || c == '-' || c == '_' || c == ' ' { c } else { '_' })
            .collect::<String>()
            .replace(' ', "-");
        format!("markdown/{}/{}.md", date, safe_title)
    };
    
    // åˆ›å»º Markdown æ–‡ä»¶
    if let Err(e) = update_markdown_file(&file_path, &req.content) {
        eprintln!("åˆ›å»º Markdown æ–‡ä»¶å¤±è´¥: {}", e);
        return HttpResponse::InternalServerError().json(serde_json::json!({
            "success": false,
            "message": format!("åˆ›å»º Markdown æ–‡ä»¶å¤±è´¥: {}", e)
        }));
    }
    
    // å¦‚æœæ²¡æœ‰æä¾›æ‘˜è¦ï¼Œåˆ™è‡ªåŠ¨ç”Ÿæˆ
    let summary = req.summary.clone().or_else(|| Some(extract_summary(&html_content)));
    
    // å¦‚æœæä¾›äº†åˆ›å»ºæ—¶é—´ï¼Œä½¿ç”¨æŒ‡å®šçš„ï¼›å¦åˆ™ä½¿ç”¨å½“å‰æ—¶é—´
    let created_at = req.created_at.as_ref()
        .and_then(|s| chrono::DateTime::parse_from_rfc3339(s).ok())
        .map(|dt| dt.with_timezone(&Utc))
        .unwrap_or(now);
    
    let passage = Passage {
        id: None,
        uuid: None,  // UUID å°†åœ¨ Repository ä¸­ç”Ÿæˆ
        title: req.title.clone(),
        content: html_content,
        original_content: Some(req.content.clone()),
        summary: summary,
        author: req.author.clone().unwrap_or_else(|| "Anonymous".to_string()),
        tags: tags_json,
        category: req.category.clone().unwrap_or_else(|| "æœªåˆ†ç±»".to_string()),
        status: req.status.clone().unwrap_or_else(|| "draft".to_string()),
        file_path: Some(file_path),
        visibility: req.visibility.clone().unwrap_or_else(|| "public".to_string()),
        is_scheduled: req.is_scheduled.unwrap_or(false),
        published_at: req.published_at.as_ref().and_then(|s| chrono::DateTime::parse_from_rfc3339(s).ok()).map(|dt| dt.with_timezone(&Utc)),
        cover_image: req.cover_image.clone().or_else(|| Some("/img/passage-cover.webp".to_string())),
        created_at,
        updated_at: now,
    };
    
    match passage_repo.create(&passage).await {
        Ok(id) => {
            // è·å–åˆšåˆ›å»ºçš„æ–‡ç« ä¿¡æ¯
            match passage_repo.get_by_id(id).await {
                Ok(created_passage) => {
                    HttpResponse::Ok().json(serde_json::json!({
                        "success": true,
                        "message": "æ–‡ç« åˆ›å»ºæˆåŠŸ",
                        "data": {
                            "id": id,
                            "uuid": created_passage.uuid.unwrap_or_else(|| String::new())
                        }
                    }))
                }
                Err(e) => {
                    eprintln!("è·å–åˆ›å»ºçš„æ–‡ç« å¤±è´¥: {}", e);
                    HttpResponse::InternalServerError().json(serde_json::json!({
                        "success": false,
                        "message": "æ–‡ç« åˆ›å»ºæˆåŠŸä½†æ— æ³•è·å–è¯¦æƒ…"
                    }))
                }
            }
        }
        Err(e) => {
            eprintln!("åˆ›å»ºæ–‡ç« å¤±è´¥: {}", e);
            HttpResponse::InternalServerError().json(serde_json::json!({
                "success": false,
                "message": "åˆ›å»ºæ–‡ç« å¤±è´¥"
            }))
        }
    }
}

/// æ›´æ–°æ–‡ç« 
pub async fn update(
    repo: web::Data<Arc<dyn Repository>>,
    path: web::Path<i64>,
    req: web::Json<UpdatePassageRequest>,
) -> HttpResponse {
    let id = path.into_inner();
    let passage_repo = PassageRepository::new(repo.get_pool().clone());
    
    // å…ˆè·å–ç°æœ‰æ–‡ç« 
    let mut passage = match passage_repo.get_by_id(id).await {
        Ok(p) => p,
        Err(e) => {
            eprintln!("è·å–æ–‡ç« å¤±è´¥: {}", e);
            return HttpResponse::NotFound().json(serde_json::json!({
                "success": false,
                "message": "æ–‡ç« ä¸å­˜åœ¨"
            }));
        }
    };
    
    // æ›´æ–°å­—æ®µ
    let mut file_updated = false;
    if let Some(ref title) = req.title {
        passage.title = title.clone();
        file_updated = true;
    }
    if let Some(ref content) = req.content {
        // è½¬æ¢ Markdown ä¸º HTML
        let html_content = convert_markdown_to_html(content);
        passage.content = html_content;
        passage.original_content = Some(content.clone());
        file_updated = true;
    }
    if let Some(ref original_content) = req.original_content {
        passage.original_content = Some(original_content.clone());
        file_updated = true;
    }
    
    // å¦‚æœå†…å®¹æˆ–æ ‡é¢˜æ›´æ–°äº†ï¼ŒåŒæ—¶æ›´æ–° Markdown æ–‡ä»¶
    if file_updated {
        if let Some(ref file_path) = passage.file_path {
            let content_to_save = passage.original_content.as_ref().unwrap_or_else(|| {
                // å¦‚æœæ²¡æœ‰åŸå§‹å†…å®¹ï¼Œä» HTML é€†å‘ç”Ÿæˆï¼ˆä¸æ¨èï¼Œä½†ä½œä¸ºåå¤‡æ–¹æ¡ˆï¼‰
                &passage.content
            });
            
            // æ›´æ–°æ–‡ä»¶åï¼ˆå¦‚æœæ ‡é¢˜æ”¹å˜äº†ï¼‰
            if let Some(ref title) = req.title {
                let new_file_path = update_markdown_file_name(file_path, title, content_to_save);
                if new_file_path != *file_path {
                    passage.file_path = Some(new_file_path);
                }
            } else {
                // æ ‡é¢˜æ²¡å˜ï¼Œåªæ›´æ–°å†…å®¹
                if let Err(e) = update_markdown_file(file_path, content_to_save) {
                    eprintln!("æ›´æ–°Markdownæ–‡ä»¶å¤±è´¥: {}", e);
                }
            }
        }
    }
    if let Some(ref summary) = req.summary {
        passage.summary = Some(summary.clone());
    }
    if let Some(ref author) = req.author {
        passage.author = author.clone();
    }
    if let Some(ref category) = req.category {
        // ç¡®ä¿åˆ†ç±»å­˜åœ¨
        let _ = ensure_category_exist(category).await;
        passage.category = category.clone();
    }
    if let Some(ref tags) = req.tags {
        // è§£ææ ‡ç­¾ JSON å¹¶ç¡®ä¿æ ‡ç­¾å­˜åœ¨äº tags è¡¨ä¸­
        if let Ok(tag_list) = serde_json::from_str::<Vec<String>>(tags) {
            let _ = ensure_tags_exist(&tag_list).await;
        }
        passage.tags = tags.clone();
    }
    if let Some(ref status) = req.status {
        passage.status = status.clone();
    }
    if let Some(ref file_path) = req.file_path {
        passage.file_path = Some(file_path.clone());
    }
    if let Some(ref visibility) = req.visibility {
        passage.visibility = visibility.clone();
    }
    if let Some(is_scheduled) = req.is_scheduled {
        passage.is_scheduled = is_scheduled;
    }
    if let Some(ref published_at) = req.published_at {
        passage.published_at = chrono::DateTime::parse_from_rfc3339(published_at)
            .ok()
            .map(|dt| dt.with_timezone(&chrono::Utc));
    }
    if let Some(ref cover_image) = req.cover_image {
        passage.cover_image = Some(cover_image.clone());
    }
    passage.updated_at = chrono::Utc::now();
    
    match passage_repo.update(&passage).await {
        Ok(_) => {
            HttpResponse::Ok().json(serde_json::json!({
                "success": true,
                "message": "æ–‡ç« æ›´æ–°æˆåŠŸ"
            }))
        }
        Err(e) => {
            eprintln!("æ›´æ–°æ–‡ç« å¤±è´¥: {}", e);
            HttpResponse::InternalServerError().json(serde_json::json!({
                "success": false,
                "message": "æ›´æ–°æ–‡ç« å¤±è´¥"
            }))
        }
    }
}

/// åˆ é™¤æ–‡ç« 
pub async fn delete(
    repo: web::Data<Arc<dyn Repository>>,
    path: web::Path<String>,
) -> HttpResponse {
    let uuid = path.into_inner();
    let passage_repo = PassageRepository::new(repo.get_pool().clone());
    let attachment_repo = AttachmentRepository::new(repo.get_pool().clone());

    // 1. è·å–æ–‡ç« ä¿¡æ¯ä»¥è·å–æ–‡ä»¶è·¯å¾„
    let passage = match passage_repo.get_by_uuid(&uuid).await {
        Ok(p) => p,
        Err(e) => {
            eprintln!("è·å–æ–‡ç« ä¿¡æ¯å¤±è´¥: {}", e);
            return HttpResponse::NotFound().json(serde_json::json!({
                "success": false,
                "message": "æ–‡ç« ä¸å­˜åœ¨"
            }));
        }
    };

    // 2. åˆ é™¤ Markdown æ–‡ä»¶
    let mut deleted_markdown = false;
    if let Some(file_path) = &passage.file_path {
        if let Err(e) = std::fs::remove_file(file_path) {
            eprintln!("åˆ é™¤ Markdown æ–‡ä»¶å¤±è´¥ {}: {}", file_path, e);
        } else {
            deleted_markdown = true;
        }
    }

    // 3. æŸ¥è¯¢å…³è”çš„é™„ä»¶
    let attachments = match attachment_repo.get_by_passage_uuids(vec![uuid.clone()]).await {
        Ok(attachments) => attachments,
        Err(e) => {
            eprintln!("æŸ¥è¯¢é™„ä»¶å¤±è´¥: {}", e);
            Vec::new()
        }
    };

    // 4. åˆ é™¤é™„ä»¶ç‰©ç†æ–‡ä»¶
    let mut deleted_files = 0;
    for attachment in &attachments {
        if let Err(e) = std::fs::remove_file(&attachment.file_path) {
            eprintln!("åˆ é™¤é™„ä»¶æ–‡ä»¶å¤±è´¥ {}: {}", attachment.file_path, e);
        } else {
            deleted_files += 1;
        }
    }

    // 5. åˆ é™¤æ–‡ç« è®°å½•
    match passage_repo.delete_by_uuid(&uuid).await {
        Ok(_) => {
            HttpResponse::Ok().json(serde_json::json!({
                "success": true,
                "message": format!("æ–‡ç« åˆ é™¤æˆåŠŸï¼Œåˆ é™¤äº† {} ä¸ª Markdown æ–‡ä»¶ï¼Œ{} ä¸ªé™„ä»¶æ–‡ä»¶", 
                    if deleted_markdown { 1 } else { 0 }, deleted_files)
            }))
        }
        Err(e) => {
            eprintln!("åˆ é™¤æ–‡ç« å¤±è´¥: {}", e);
            HttpResponse::InternalServerError().json(serde_json::json!({
                "success": false,
                "message": "åˆ é™¤æ–‡ç« å¤±è´¥"
            }))
        }
    }
}

/// æ‰¹é‡åˆ é™¤æ–‡ç« è¯·æ±‚
#[derive(Debug, Deserialize)]
pub struct BatchDeleteRequest {
    pub ids: Vec<i64>,
}

/// æ‰¹é‡åˆ é™¤æ–‡ç« 
pub async fn delete_batch(
    repo: web::Data<Arc<dyn Repository>>,
    req: web::Json<BatchDeleteRequest>,
) -> HttpResponse {
    if req.ids.is_empty() {
        return HttpResponse::BadRequest().json(serde_json::json!({
            "success": false,
            "message": "æ–‡ç« IDåˆ—è¡¨ä¸èƒ½ä¸ºç©º"
        }));
    }

    let passage_repo = PassageRepository::new(repo.get_pool().clone());
    let attachment_repo = AttachmentRepository::new(repo.get_pool().clone());

    // 1. è·å–æ–‡ç«  UUID åˆ—è¡¨å’Œæ–‡ä»¶è·¯å¾„
    let mut uuids = Vec::new();
    let mut file_paths = Vec::new();
    
    for id in &req.ids {
        match passage_repo.get_by_id(*id).await {
            Ok(passage) => {
                if let Some(uuid) = &passage.uuid {
                    uuids.push(uuid.clone());
                }
                if let Some(file_path) = &passage.file_path {
                    file_paths.push(file_path.clone());
                }
            }
            Err(e) => {
                eprintln!("è·å–æ–‡ç« ä¿¡æ¯å¤±è´¥ ID={}: {}", id, e);
            }
        }
    }

    // 2. åˆ é™¤ Markdown æ–‡ä»¶
    let mut deleted_markdown_files = 0;
    for file_path in &file_paths {
        if let Err(e) = std::fs::remove_file(file_path) {
            eprintln!("åˆ é™¤ Markdown æ–‡ä»¶å¤±è´¥ {}: {}", file_path, e);
        } else {
            deleted_markdown_files += 1;
        }
    }

    // 3. æŸ¥è¯¢å…³è”çš„é™„ä»¶
    let attachments = match attachment_repo.get_by_passage_uuids(uuids.clone()).await {
        Ok(attachments) => attachments,
        Err(e) => {
            eprintln!("æŸ¥è¯¢é™„ä»¶å¤±è´¥: {}", e);
            // å³ä½¿æŸ¥è¯¢é™„ä»¶å¤±è´¥ï¼Œä¹Ÿç»§ç»­åˆ é™¤æ–‡ç« 
            Vec::new()
        }
    };

    // 4. åˆ é™¤é™„ä»¶ç‰©ç†æ–‡ä»¶
    let mut deleted_files = 0;
    for attachment in &attachments {
        if let Err(e) = std::fs::remove_file(&attachment.file_path) {
            eprintln!("åˆ é™¤é™„ä»¶æ–‡ä»¶å¤±è´¥ {}: {}", attachment.file_path, e);
        } else {
            deleted_files += 1;
        }
    }

    // 5. åˆ é™¤æ–‡ç« è®°å½•ï¼ˆä¼šè‡ªåŠ¨åˆ é™¤å…³è”çš„æ•°æ®åº“è®°å½•ï¼Œé€šè¿‡ CASCADEï¼‰
    match passage_repo.delete_batch(req.ids.clone()).await {
        Ok(count) => {
            HttpResponse::Ok().json(serde_json::json!({
                "success": true,
                "message": format!("æˆåŠŸåˆ é™¤ {} ç¯‡æ–‡ç« ï¼Œ{} ä¸ª Markdown æ–‡ä»¶ï¼Œ{} ä¸ªé™„ä»¶æ–‡ä»¶", count, deleted_markdown_files, deleted_files),
                "deleted_count": count,
                "deleted_markdown_files": deleted_markdown_files,
                "deleted_files": deleted_files
            }))
        }
        Err(e) => {
            eprintln!("æ‰¹é‡åˆ é™¤æ–‡ç« å¤±è´¥: {}", e);
            HttpResponse::InternalServerError().json(serde_json::json!({
                "success": false,
                "message": "æ‰¹é‡åˆ é™¤æ–‡ç« å¤±è´¥"
            }))
        }
    }
}

/// ä» HTML å†…å®¹ä¸­æå–æ‘˜è¦
fn extract_summary(html_content: &str) -> String {
    // ç§»é™¤ HTML æ ‡ç­¾
    let re = regex::Regex::new(r"<[^>]*>").unwrap();
    let text = re.replace_all(html_content, "");
    
    // ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    let text: String = text.split_whitespace().collect::<Vec<&str>>().join(" ");
    
    // æŒ‰å­—ç¬¦æˆªå–å‰ 200 ä¸ªå­—ç¬¦ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰
    let chars: Vec<char> = text.chars().collect();
    if chars.len() > 200 {
        format!("{}...", chars[..200].iter().collect::<String>())
    } else {
        text
    }
}

/// å°† Markdown è½¬æ¢ä¸º HTMLï¼ˆå¸¦ç¼“å­˜ï¼‰
fn convert_markdown_to_html(markdown: &str) -> String {
    use pulldown_cmark::{Parser, html, Options};
    use std::collections::HashMap;
    use std::sync::Mutex;
    use once_cell::sync::Lazy;

    // ä½¿ç”¨å†…å®¹å“ˆå¸Œä½œä¸ºç¼“å­˜é”®
    let mut hasher = md5::Md5::default();
    md5::Digest::update(&mut hasher, markdown.as_bytes());
    let content_hash = format!("{:x}", md5::Digest::finalize(hasher));

    // é™æ€ç¼“å­˜ï¼šå†…å®¹å“ˆå¸Œ -> HTML
    static RENDER_CACHE: Lazy<Mutex<HashMap<String, String>>> = Lazy::new(|| {
        Mutex::new(HashMap::new())
    });

    // æ£€æŸ¥ç¼“å­˜
    {
        let cache = RENDER_CACHE.lock().unwrap();
        if let Some(cached_html) = cache.get(&content_hash) {
            return cached_html.clone();
        }
    }

    // ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œæ¸²æŸ“
    let mut options = Options::empty();
    options.insert(Options::ENABLE_TABLES);
    options.insert(Options::ENABLE_STRIKETHROUGH);
    options.insert(Options::ENABLE_TASKLISTS);

    let parser = Parser::new_ext(markdown, options);
    let mut html_output = String::new();
    html::push_html(&mut html_output, parser);

    // å­˜å…¥ç¼“å­˜
    {
        let mut cache = RENDER_CACHE.lock().unwrap();
        // é™åˆ¶ç¼“å­˜å¤§å°ä¸º 1000 æ¡
        if cache.len() >= 1000 {
            // ç®€å•ç­–ç•¥ï¼šæ¸…ç©ºä¸€åŠç¼“å­˜
            let keys_to_remove: Vec<_> = cache.keys().take(500).cloned().collect();
            for key in keys_to_remove {
                cache.remove(&key);
            }
        }
        cache.insert(content_hash, html_output.clone());
    }

    html_output
}

/// ç¡®ä¿æ ‡ç­¾å­˜åœ¨äº tags è¡¨ä¸­
async fn ensure_tags_exist(tag_names: &[String]) -> Result<(), String> {
    use crate::db::get_db_pool_sync;
    use crate::db::repositories::TagRepository;
    use std::sync::Arc;

    let pool = get_db_pool_sync().map_err(|e| format!("è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: {}", e))?;
    let tag_repo = TagRepository::new(Arc::new(pool.clone()));

    for tag_name in tag_names {
        // æŸ¥æ‰¾æ ‡ç­¾ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        if tag_repo.get_by_name(tag_name).await.is_err() {
            let now = chrono::Utc::now();
            let new_tag = crate::db::models::Tag {
                id: None,
                name: tag_name.clone(),
                description: format!("ç”¨æˆ·åˆ›å»ºçš„æ ‡ç­¾: {}", tag_name),
                color: "#007bff".to_string(),
                category_id: 0,
                sort_order: 0,
                is_enabled: true,
                created_at: now,
                updated_at: now,
            };

            tag_repo.create(&new_tag).await
                .map_err(|e| format!("åˆ›å»ºæ ‡ç­¾å¤±è´¥: {}", e))?;
        }
    }

    Ok(())
}

/// ç¡®ä¿åˆ†ç±»å­˜åœ¨äº categories è¡¨ä¸­
async fn ensure_category_exist(category_name: &str) -> Result<(), String> {
    use crate::db::get_db_pool_sync;
    use crate::db::repositories::CategoryRepository;
    use std::sync::Arc;

    // å¦‚æœåˆ†ç±»ä¸ºç©ºæˆ–"æœªåˆ†ç±»"ï¼Œè·³è¿‡
    if category_name.is_empty() || category_name == "æœªåˆ†ç±»" {
        return Ok(());
    }

    let pool = get_db_pool_sync().map_err(|e| format!("è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: {}", e))?;
    let category_repo = CategoryRepository::new(Arc::new(pool.clone()));

    // æŸ¥æ‰¾åˆ†ç±»ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
    if category_repo.get_by_name(category_name).await.is_err() {
        let now = chrono::Utc::now();
        let new_category = crate::db::models::Category {
            id: None,
            name: category_name.to_string(),
            description: format!("ç”¨æˆ·åˆ›å»ºçš„åˆ†ç±»: {}", category_name),
            icon: "ğŸ“".to_string(),
            sort_order: 0,
            is_enabled: true,
            created_at: now,
            updated_at: now,
        };

        category_repo.create(&new_category).await
            .map_err(|e| format!("åˆ›å»ºåˆ†ç±»å¤±è´¥: {}", e))?;
    }

    Ok(())
}

/// æ›´æ–° Markdown æ–‡ä»¶
fn update_markdown_file(file_path: &str, content: &str) -> Result<(), String> {
    use std::fs;
    use std::path::Path;
    
    // åˆ›å»ºç›®å½•
    if let Some(parent) = Path::new(file_path).parent() {
        fs::create_dir_all(parent)
            .map_err(|e| format!("åˆ›å»ºç›®å½•å¤±è´¥: {}", e))?;
    }
    
    // å†™å…¥æ–‡ä»¶
    fs::write(file_path, content)
        .map_err(|e| format!("å†™å…¥æ–‡ä»¶å¤±è´¥: {}", e))?;
    
    Ok(())
}

/// æ›´æ–° Markdown æ–‡ä»¶åï¼ˆå¦‚æœæ ‡é¢˜æ”¹å˜ï¼‰
fn update_markdown_file_name(old_path: &str, new_title: &str, content: &str) -> String {
    use std::fs;
    use std::path::Path;
    
    // æ„å»ºæ–°æ–‡ä»¶è·¯å¾„
    if let Some(parent) = Path::new(old_path).parent() {
        let new_path = parent.join(format!("{}.md", new_title));
        
        // åˆ é™¤æ—§æ–‡ä»¶
        let _ = fs::remove_file(old_path);
        
        // åˆ›å»ºæ–°æ–‡ä»¶
        if let Err(e) = update_markdown_file(new_path.to_str().unwrap(), content) {
            eprintln!("æ›´æ–°æ–‡ä»¶åå¤±è´¥: {}", e);
            return old_path.to_string();
        }
        
        new_path.to_str().map(|s| s.to_string()).unwrap_or_else(|| old_path.to_string())
    } else {
        old_path.to_string()
    }
}

/// é€šè¿‡æŸ¥è¯¢å‚æ•°æ›´æ–°æ–‡ç« ï¼ˆç”¨äºç®¡ç†åå°ï¼‰
pub async fn update_by_query(
    repo: web::Data<Arc<dyn Repository>>,
    query: web::Query<std::collections::HashMap<String, String>>,
    req_json: web::Json<UpdatePassageRequest>,
    http_req: actix_web::HttpRequest,
) -> HttpResponse {
    // é‰´æƒæ£€æŸ¥
    if http_req.cookie("auth_token").is_none() {
        return crate::middleware::auth::missing_token_response();
    }
    if crate::middleware::auth::check_admin_auth(&http_req).is_none() {
        return crate::middleware::auth::forbidden_response();
    }

    let passage_repo = PassageRepository::new(repo.get_pool().clone());
    
    // ä»æŸ¥è¯¢å‚æ•°ä¸­è·å–æ–‡ç«  ID
    let id: i64 = match query.get("id").and_then(|s| s.parse().ok()) {
        Some(id) => id,
        None => {
            return HttpResponse::BadRequest().json(serde_json::json!({
                "success": false,
                "message": "ç¼ºå°‘æ–‡ç«  ID å‚æ•°"
            }));
        }
    };
    
    // å…ˆè·å–ç°æœ‰æ–‡ç« 
    let mut passage = match passage_repo.get_by_id(id).await {
        Ok(p) => p,
        Err(e) => {
            eprintln!("è·å–æ–‡ç« å¤±è´¥: {}", e);
            return HttpResponse::NotFound().json(serde_json::json!({
                "success": false,
                "message": "æ–‡ç« ä¸å­˜åœ¨"
            }));
        }
    };
    
    // æ›´æ–°å­—æ®µ
    let mut file_updated = false;
    if let Some(ref title) = req_json.title {
        passage.title = title.clone();
        file_updated = true;
    }
    if let Some(ref content) = req_json.content {
        // è½¬æ¢ Markdown ä¸º HTML
        let html_content = convert_markdown_to_html(content);
        passage.content = html_content;
        passage.original_content = Some(content.clone());
        file_updated = true;
    }
    if let Some(ref original_content) = req_json.original_content {
        passage.original_content = Some(original_content.clone());
        file_updated = true;
    }
    
    // å¦‚æœå†…å®¹æˆ–æ ‡é¢˜æ›´æ–°äº†ï¼ŒåŒæ—¶æ›´æ–° Markdown æ–‡ä»¶
    if file_updated {
        if let Some(ref file_path) = passage.file_path {
            let content_to_save = passage.original_content.as_ref().unwrap_or_else(|| {
                // å¦‚æœæ²¡æœ‰åŸå§‹å†…å®¹ï¼Œä» HTML é€†å‘ç”Ÿæˆï¼ˆä¸æ¨èï¼Œä½†ä½œä¸ºåå¤‡æ–¹æ¡ˆï¼‰
                &passage.content
            });
            
            // æ›´æ–°æ–‡ä»¶åï¼ˆå¦‚æœæ ‡é¢˜æ”¹å˜äº†ï¼‰
            if let Some(ref title) = req_json.title {
                let new_file_path = update_markdown_file_name(file_path, title, content_to_save);
                if new_file_path != *file_path {
                    passage.file_path = Some(new_file_path);
                }
            } else {
                // æ ‡é¢˜æ²¡å˜ï¼Œåªæ›´æ–°å†…å®¹
                if let Err(e) = update_markdown_file(file_path, content_to_save) {
                    eprintln!("æ›´æ–°Markdownæ–‡ä»¶å¤±è´¥: {}", e);
                }
            }
        }
    }
    if let Some(ref summary) = req_json.summary {
        passage.summary = Some(summary.clone());
    }
    if let Some(ref author) = req_json.author {
        passage.author = author.clone();
    }
    if let Some(ref tags) = req_json.tags {
        // è§£ææ ‡ç­¾ JSON å¹¶ç¡®ä¿æ ‡ç­¾å­˜åœ¨äº tags è¡¨ä¸­
        if let Ok(tag_list) = serde_json::from_str::<Vec<String>>(tags) {
            let _ = ensure_tags_exist(&tag_list).await;
        }
        passage.tags = tags.clone();
    }
    if let Some(ref category) = req_json.category {
        passage.category = category.clone();
    }
    if let Some(ref status) = req_json.status {
        passage.status = status.clone();
    }
    if let Some(ref file_path) = req_json.file_path {
        passage.file_path = Some(file_path.clone());
    }
    if let Some(ref visibility) = req_json.visibility {
        passage.visibility = visibility.clone();
    }
    if let Some(is_scheduled) = req_json.is_scheduled {
        passage.is_scheduled = is_scheduled;
    }
    if let Some(ref published_at) = req_json.published_at {
        passage.published_at = chrono::DateTime::parse_from_rfc3339(published_at)
            .ok()
            .map(|dt| dt.with_timezone(&chrono::Utc));
    }
    if let Some(ref cover_image) = req_json.cover_image {
        passage.cover_image = Some(cover_image.clone());
    }
    passage.updated_at = chrono::Utc::now();
    
    match passage_repo.update(&passage).await {
        Ok(_) => {
            HttpResponse::Ok().json(serde_json::json!({
                "success": true,
                "message": "æ–‡ç« æ›´æ–°æˆåŠŸ"
            }))
        }
        Err(e) => {
            eprintln!("æ›´æ–°æ–‡ç« å¤±è´¥: {}", e);
            HttpResponse::InternalServerError().json(serde_json::json!({
                "success": false,
                "message": "æ›´æ–°æ–‡ç« å¤±è´¥"
            }))
        }
    }
}

// é€šè¿‡æŸ¥è¯¢å‚æ•°åˆ é™¤æ–‡ç« ï¼ˆç”¨äºç®¡ç†åå°ï¼‰
pub async fn delete_by_query(
    repo: web::Data<Arc<dyn Repository>>,
    query: web::Query<std::collections::HashMap<String, String>>,
    http_req: actix_web::HttpRequest,
) -> HttpResponse {
    // é‰´æƒæ£€æŸ¥
    if http_req.cookie("auth_token").is_none() {
        return crate::middleware::auth::missing_token_response();
    }
    if crate::middleware::auth::check_admin_auth(&http_req).is_none() {
        return crate::middleware::auth::forbidden_response();
    }
    let passage_repo = PassageRepository::new(repo.get_pool().clone());
    let attachment_repo = AttachmentRepository::new(repo.get_pool().clone());
    
    // ä»æŸ¥è¯¢å‚æ•°ä¸­è·å–æ–‡ç«  ID
    let id: i64 = match query.get("id").and_then(|s| s.parse().ok()) {
        Some(id) => id,
        None => {
            return HttpResponse::BadRequest().json(serde_json::json!({
                "success": false,
                "message": "ç¼ºå°‘æ–‡ç«  ID å‚æ•°"
            }));
        }
    };
    
    // è·å–æ–‡ç« ä¿¡æ¯ï¼ˆåŒ…å«æ–‡ä»¶è·¯å¾„å’Œ UUIDï¼‰
    let passage = match passage_repo.get_by_id(id).await {
        Ok(p) => p,
        Err(e) => {
            return HttpResponse::NotFound().json(serde_json::json!({
                "success": false,
                "message": format!("è·å–æ–‡ç« å¤±è´¥: {}", e)
            }));
        }
    };
    
    let uuid = match &passage.uuid {
        Some(u) => u.clone(),
        None => {
            return HttpResponse::NotFound().json(serde_json::json!({
                "success": false,
                "message": "æ–‡ç«  UUID ä¸å­˜åœ¨"
            }));
        }
    };
    
    // åˆ é™¤ Markdown æ–‡ä»¶
    if let Some(file_path) = &passage.file_path {
        if let Err(e) = std::fs::remove_file(file_path) {
            eprintln!("åˆ é™¤ Markdown æ–‡ä»¶å¤±è´¥ {}: {}", file_path, e);
        }
    }
    
    // æŸ¥è¯¢å…³è”çš„é™„ä»¶
    let attachments = match attachment_repo.get_by_passage_uuids(vec![uuid.clone()]).await {
        Ok(attachments) => attachments,
        Err(e) => {
            eprintln!("æŸ¥è¯¢é™„ä»¶å¤±è´¥: {}", e);
            Vec::new()
        }
    };
    
    // åˆ é™¤é™„ä»¶ç‰©ç†æ–‡ä»¶
    let mut deleted_files = 0;
    for attachment in &attachments {
        if let Err(e) = std::fs::remove_file(&attachment.file_path) {
            eprintln!("åˆ é™¤é™„ä»¶æ–‡ä»¶å¤±è´¥ {}: {}", attachment.file_path, e);
        } else {
            deleted_files += 1;
        }
    }
    
    // åˆ é™¤æ–‡ç« è®°å½•
    match passage_repo.delete_by_uuid(&uuid).await {
        Ok(_) => {
            HttpResponse::Ok().json(serde_json::json!({
                "success": true,
                "message": format!("æ–‡ç« åˆ é™¤æˆåŠŸï¼Œåˆ é™¤äº† {} ä¸ªé™„ä»¶æ–‡ä»¶", deleted_files)
            }))
        }
        Err(e) => {
            eprintln!("åˆ é™¤æ–‡ç« å¤±è´¥: {}", e);
            HttpResponse::InternalServerError().json(serde_json::json!({
                "success": false,
                "message": "åˆ é™¤æ–‡ç« å¤±è´¥"
            }))
        }
    }
}

/// é€šè¿‡æŸ¥è¯¢å‚æ•°è·å–å•ç¯‡æ–‡ç« æˆ–æ–‡ç« åˆ—è¡¨ï¼ˆç”¨äºç®¡ç†åå°ï¼‰
pub async fn get_by_query(
    repo: web::Data<Arc<dyn Repository>>,
    query: web::Query<std::collections::HashMap<String, String>>,
    http_req: HttpRequest,
) -> HttpResponse {
    // é‰´æƒæ£€æŸ¥
    if http_req.cookie("auth_token").is_none() {
        return crate::middleware::auth::missing_token_response();
    }
    if crate::middleware::auth::check_admin_auth(&http_req).is_none() {
        return crate::middleware::auth::forbidden_response();
    }
    let passage_repo = PassageRepository::new(repo.get_pool().clone());
    
    // æ£€æŸ¥æ˜¯å¦æœ‰ id æŸ¥è¯¢å‚æ•°
    if let Some(id_str) = query.get("id") {
        // å¦‚æœæœ‰ id å‚æ•°ï¼Œè¿”å›å•ç¯‡æ–‡ç« 
        let id: i64 = match id_str.parse() {
            Ok(id) => id,
            Err(_) => {
                return HttpResponse::BadRequest().json(serde_json::json!({
                    "success": false,
                    "message": "æ— æ•ˆçš„æ–‡ç«  ID"
                }));
            }
        };
        
        match passage_repo.get_by_id(id).await {
            Ok(passage) => {
                let response = PassageResponse {
                    id: passage.id.unwrap_or(0),
                    uuid: passage.uuid.unwrap_or_default(),
                    title: passage.title,
                    content: passage.original_content.unwrap_or_default(), // è¿”å›åŸå§‹ Markdown å†…å®¹
                    html_content: Some(passage.content), // è¿”å›æ¸²æŸ“åçš„ HTML
                    summary: passage.summary,
                    author: passage.author,
                    tags: passage.tags,
                    category: passage.category,
                    status: passage.status,
                    file_path: passage.file_path,
                    visibility: passage.visibility,
                    is_scheduled: passage.is_scheduled,
                    published_at: passage.published_at.map(|d| d.format("%Y-%m-%d %H:%M:%S").to_string()),
                    cover_image: passage.cover_image,
                    created_at: passage.created_at.format("%Y-%m-%d %H:%M:%S").to_string(),
                    updated_at: passage.updated_at.format("%Y-%m-%d %H:%M:%S").to_string(),
                };
                
                HttpResponse::Ok().json(serde_json::json!({
                    "success": true,
                    "data": response
                }))
            }
            Err(e) => {
                eprintln!("è·å–æ–‡ç« å¤±è´¥: {}", e);
                HttpResponse::NotFound().json(serde_json::json!({
                    "success": false,
                    "message": "æ–‡ç« ä¸å­˜åœ¨"
                }))
            }
        }
    } else {
        // å¦‚æœæ²¡æœ‰ id å‚æ•°ï¼Œè¿”å›æ–‡ç« åˆ—è¡¨ï¼ˆè°ƒç”¨ admin_list çš„é€»è¾‘ï¼‰
        let limit: i64 = query.get("limit").and_then(|l| l.parse().ok()).unwrap_or(20);
        let _offset: i64 = query.get("offset").and_then(|o| o.parse().ok()).unwrap_or(0);
        let page: i64 = query.get("page").and_then(|p| p.parse().ok()).unwrap_or(1);
        let calculated_offset = (page - 1) * limit;
        
        match passage_repo.get_all(limit, calculated_offset).await {
            Ok(passages) => {
                let total = match passage_repo.count().await {
                    Ok(c) => c,
                    Err(_) => passages.len() as i64,
                };
                
                let data: Vec<PassageResponse> = passages.into_iter()
                    .map(|p| PassageResponse {
                        id: p.id.unwrap_or(0),
                        uuid: p.uuid.unwrap_or_default(),
                        title: p.title,
                        content: p.original_content.unwrap_or_default(), // è¿”å›åŸå§‹ Markdown å†…å®¹
                        html_content: Some(p.content), // è¿”å›æ¸²æŸ“åçš„ HTML
                        summary: p.summary,
                        author: p.author,
                        tags: p.tags,
                        category: p.category,
                        status: p.status,
                        file_path: p.file_path,
                        visibility: p.visibility,
                        is_scheduled: p.is_scheduled,
                        published_at: p.published_at.map(|d| d.format("%Y-%m-%d %H:%M:%S").to_string()),
                        cover_image: p.cover_image,
                        created_at: p.created_at.format("%Y-%m-%d %H:%M:%S").to_string(),
                        updated_at: p.updated_at.format("%Y-%m-%d %H:%M:%S").to_string(),
                    })
                    .collect();
                
                HttpResponse::Ok().json(serde_json::json!({
                    "success": true,
                    "data": data,
                    "total": total,
                    "page": page,
                    "limit": limit
                }))
            }
            Err(e) => {
                eprintln!("è·å–æ–‡ç« åˆ—è¡¨å¤±è´¥: {}", e);
                HttpResponse::InternalServerError().json(serde_json::json!({
                    "success": false,
                    "message": "è·å–æ–‡ç« åˆ—è¡¨å¤±è´¥"
                }))
            }
        }
    }
}