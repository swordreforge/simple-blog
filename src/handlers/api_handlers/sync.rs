use actix_web::{web, HttpResponse};
use serde::Serialize;
use crate::db::repositories::{PassageRepository, Repository};
use std::sync::Arc;
use std::path::{Path, PathBuf};
use std::fs;
use chrono::{Utc, NaiveDate, DateTime};

/// åŒæ­¥å“åº”
#[derive(Debug, Serialize)]
pub struct SyncResponse {
    pub success: bool,
    pub message: String,
}

/// åŒæ­¥ç»“æœ
#[derive(Debug)]
pub struct SyncResult {
    pub synced_count: usize,
    pub updated_count: usize,
    pub deleted_count: usize,
    pub message: String,
}

/// åŒæ­¥å¤„ç†å™¨ - ä» markdown ç›®å½•åŒæ­¥æ–‡ç« åˆ°æ•°æ®åº“
pub async fn sync(repo: web::Data<Arc<dyn Repository>>) -> HttpResponse {
    let passage_repo = PassageRepository::new(repo.get_pool().clone());
    
    // éå† markdown ç›®å½•
    let markdown_dir = Path::new("markdown");
    
    if !markdown_dir.exists() {
        return HttpResponse::Ok().json(SyncResponse {
            success: false,
            message: "markdown ç›®å½•ä¸å­˜åœ¨".to_string(),
        });
    }
    
    let mut synced_count = 0;
    let mut updated_count = 0;
    let mut deleted_count = 0;
    
    // é€’å½’éå†ç›®å½•å¹¶åŒæ­¥æ–‡ä»¶
    match sync_directory_async(markdown_dir, &passage_repo, &mut synced_count, &mut updated_count, &mut deleted_count).await {
        Ok(_) => {
            HttpResponse::Ok().json(SyncResponse {
                success: true,
                message: format!("åŒæ­¥æˆåŠŸ: {} ç¯‡æ–‡ç« å·²åŒæ­¥, {} ç¯‡æ–‡ç« å·²æ›´æ–°, {} ç¯‡æ–‡ç« å·²åˆ é™¤", synced_count, updated_count, deleted_count),
            })
        }
        Err(e) => {
            HttpResponse::Ok().json(SyncResponse {
                success: false,
                message: format!("åŒæ­¥å¤±è´¥: {}", e),
            })
        }
    }
}

/// å†…éƒ¨åŒæ­¥å‡½æ•° - ç”¨äºå¯åŠ¨æ—¶çš„è‡ªåŠ¨åŒæ­¥
pub async fn sync_directory_internal(passage_repo: &PassageRepository) -> Result<SyncResult, String> {
    let markdown_dir = Path::new("markdown");
    
    if !markdown_dir.exists() {
        return Ok(SyncResult {
            synced_count: 0,
            updated_count: 0,
            deleted_count: 0,
            message: "markdown ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡åŒæ­¥".to_string(),
        });
    }
    
    let mut synced_count = 0;
    let mut updated_count = 0;
    let mut deleted_count = 0;
    
    sync_directory_async(markdown_dir, passage_repo, &mut synced_count, &mut updated_count, &mut deleted_count).await?;
    
    Ok(SyncResult {
        synced_count,
        updated_count,
        deleted_count,
        message: format!(
            "æ–‡ç« åŒæ­¥å®Œæˆ: {} ç¯‡å·²åŒæ­¥, {} ç¯‡å·²æ›´æ–°, {} ç¯‡å·²åˆ é™¤",
            synced_count, updated_count, deleted_count
        ),
    })
}

/// å¼‚æ­¥åŒæ­¥ç›®å½•ï¼ˆä½¿ç”¨è¿­ä»£è€Œéé€’å½’ï¼‰
async fn sync_directory_async(
    dir: &Path,
    passage_repo: &PassageRepository,
    synced_count: &mut usize,
    updated_count: &mut usize,
    deleted_count: &mut usize,
) -> Result<(), String> {
    // ä½¿ç”¨æ˜¾å¼æ ˆæ¥æ¨¡æ‹Ÿé€’å½’
    let mut dir_stack: Vec<PathBuf> = vec![dir.to_path_buf()];
    let mut md_files: Vec<PathBuf> = Vec::new();
    
    while let Some(current_dir) = dir_stack.pop() {
        let entries = fs::read_dir(&current_dir).map_err(|e| format!("è¯»å–ç›®å½•å¤±è´¥: {}", e))?;
        
        for entry in entries {
            let entry = entry.map_err(|e| format!("è¯»å–æ¡ç›®å¤±è´¥: {}", e))?;
            let path = entry.path();
            
            if path.is_dir() {
                dir_stack.push(path);
            } else if path.extension().map_or(false, |ext| ext == "md") {
                md_files.push(path);
            }
        }
    }
    
    // åŒæ­¥æ‰€æœ‰ markdown æ–‡ä»¶
    for path in md_files {
        match sync_markdown_file_async(&path, passage_repo, synced_count, updated_count).await {
            Ok(_) => {}
            Err(e) => {
                eprintln!("åŒæ­¥æ–‡ä»¶å¤±è´¥ {}: {}", path.display(), e);
            }
        }
    }
    
    // æ¸…ç†æ•°æ®åº“ä¸­ä¸å­˜åœ¨çš„æ–‡ä»¶è®°å½•
    cleanup_orphaned_passages(passage_repo, dir, deleted_count).await?;
    
    Ok(())
}

/// å¼‚æ­¥åŒæ­¥å•ä¸ª markdown æ–‡ä»¶
async fn sync_markdown_file_async(
    path: &Path,
    passage_repo: &PassageRepository,
    synced_count: &mut usize,
    updated_count: &mut usize,
) -> Result<(), String> {
    // è¯»å–æ–‡ä»¶å†…å®¹
    let content = fs::read_to_string(path)
        .map_err(|e| format!("è¯»å–æ–‡ä»¶å¤±è´¥: {}", e))?;
    
    // æå–æ ‡é¢˜ï¼ˆä»æ–‡ä»¶åï¼‰
    let title = path.file_stem()
        .and_then(|s| s.to_str())
        .unwrap_or("æœªå‘½åæ–‡ç« ")
        .to_string();
    
    // è·å–ç›¸å¯¹è·¯å¾„
    let file_path = path.to_string_lossy().to_string();
    
    // ä»è·¯å¾„æå–æ—¥æœŸï¼ˆæ ¼å¼ï¼šmarkdown/YYYY/MM/DD/filename.mdï¼‰
    let created_at = extract_date_from_path(&file_path).unwrap_or_else(Utc::now);
    
    // è½¬æ¢ markdown ä¸º HTML
    let html_content = convert_markdown_to_html(&content);
    
    // ç”Ÿæˆæ‘˜è¦
    let summary = extract_summary(&html_content);
    
    // ç”Ÿæˆæ ‡ç­¾
    let tags = extract_tags(&file_path);
    
    let now = Utc::now();
    
    // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    if let Ok(existing) = passage_repo.get_by_file_path(&file_path).await {
        // æ›´æ–°ç°æœ‰æ–‡ç« 
        let updated_passage = crate::db::models::Passage {
            id: existing.id,
            title,
            content: html_content,
            original_content: Some(content.clone()),
            summary,
            author: existing.author,
            tags,
            category: existing.category,
            status: existing.status,
            file_path: Some(file_path.clone()),
            visibility: existing.visibility,
            is_scheduled: existing.is_scheduled,
            published_at: existing.published_at,
            created_at: existing.created_at,
            updated_at: now,
        };
        
        // æ›´æ–°æ–‡ç« ï¼ˆä½¿ç”¨ SQL ç›´æ¥æ›´æ–°ï¼‰
        update_passage(passage_repo, &updated_passage).await
            .map_err(|e| format!("æ›´æ–°æ–‡ç« å¤±è´¥: {}", e))?;
        *updated_count += 1;
        println!("âœï¸  å·²æ›´æ–°æ–‡ç« : {}", file_path);
    } else {
        // åˆ›å»ºæ–°æ–‡ç« 
        let passage = crate::db::models::Passage {
            id: None,
            title: title.clone(),
            content: html_content,
            original_content: Some(content.clone()),
            summary,
            author: "Admin".to_string(),
            tags,
            category: "æœªåˆ†ç±»".to_string(),
            status: "published".to_string(),
            file_path: Some(file_path.clone()),
            visibility: "public".to_string(),
            is_scheduled: false,
            published_at: None,
            created_at,
            updated_at: now,
        };
        
        passage_repo.create(&passage).await
            .map_err(|e| format!("åˆ›å»ºæ–‡ç« å¤±è´¥: {}", e))?;
        *synced_count += 1;
        println!("âœ… å·²åŒæ­¥æ–‡ç« : {}", file_path);
    }
    
    Ok(())
}

/// ä»æ–‡ä»¶è·¯å¾„æå–æ—¥æœŸ
fn extract_date_from_path(file_path: &str) -> Option<DateTime<Utc>> {
    // ç§»é™¤ markdown/ å‰ç¼€
    let path = file_path.strip_prefix("markdown/")?;
    
    // åˆ†å‰²è·¯å¾„
    let parts: Vec<&str> = path.split('/').collect();
    
    // æ£€æŸ¥æ˜¯å¦æœ‰ å¹´/æœˆ/æ—¥ æ ¼å¼
    if parts.len() >= 3 {
        let year = parts[0].parse::<i32>().ok()?;
        let month = parts[1].parse::<u32>().ok()?;
        let day = parts[2].parse::<u32>().ok()?;
        
        if let Some(naive_date) = NaiveDate::from_ymd_opt(year, month, day) {
            return Some(DateTime::<Utc>::from_naive_utc_and_offset(
                naive_date.and_hms_opt(0, 0, 0).unwrap(),
                Utc,
            ));
        }
    }
    
    None
}

/// æå–æ‘˜è¦
fn extract_summary(html_content: &str) -> Option<String> {
    use regex::Regex;
    
    // ç§»é™¤ HTML æ ‡ç­¾
    let re = Regex::new(r"<[^>]*>").unwrap();
    let text = re.replace_all(html_content, "");
    
    // ç§»é™¤å¤šä½™çš„ç©ºç™½
    let text: String = text.split_whitespace().collect::<Vec<&str>>().join(" ");
    
    // æˆªå–å‰ 200 ä¸ªå­—ç¬¦
    if text.chars().count() > 200 {
        Some(text.chars().take(200).collect::<String>() + "...")
    } else {
        Some(text)
    }
}

/// æå–æ ‡ç­¾
fn extract_tags(path: &str) -> String {
    // ç§»é™¤ markdown/ å‰ç¼€å’Œ .md åç¼€
    let path = path.strip_prefix("markdown/").unwrap_or(path);
    let path = path.strip_suffix(".md").unwrap_or(path);
    
    // åˆ†å‰²è·¯å¾„
    let parts: Vec<&str> = path.split('/').collect();
    
    // ä½¿ç”¨å¹´ä»½å’Œæœˆä»½ä½œä¸ºæ ‡ç­¾
    let mut tags = Vec::new();
    if parts.len() >= 2 {
        tags.push(format!("\"{}\"", parts[0]));  // å¹´ä»½
        tags.push(format!("\"{}\"", parts[1]));  // æœˆä»½
    }
    
    // è½¬æ¢ä¸º JSON æ ¼å¼
    if tags.is_empty() {
        "[]".to_string()
    } else {
        format!("[{}]", tags.join(","))
    }
}

/// æ›´æ–°æ–‡ç« 
async fn update_passage(
    passage_repo: &PassageRepository,
    passage: &crate::db::models::Passage,
) -> Result<(), String> {
    use crate::db::get_db_pool_sync;
    use rusqlite::params;
    
    let pool = get_db_pool_sync().map_err(|e| format!("è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: {}", e))?;
    let conn = pool.get().map_err(|e| format!("è·å–è¿æ¥å¤±è´¥: {}", e))?;
    
    if let Some(id) = passage.id {
        conn.execute(
            "UPDATE passages SET title = ?, content = ?, original_content = ?, summary = ?, tags = ?, updated_at = ? WHERE id = ?",
            params![
                &passage.title,
                &passage.content,
                &passage.original_content,
                &passage.summary,
                &passage.tags,
                &passage.updated_at,
                id,
            ],
        ).map_err(|e| format!("æ›´æ–°å¤±è´¥: {}", e))?;
    }
    
    Ok(())
}

/// æ¸…ç†æ•°æ®åº“ä¸­ä¸å­˜åœ¨çš„æ–‡ç« è®°å½•
async fn cleanup_orphaned_passages(
    passage_repo: &PassageRepository,
    markdown_dir: &Path,
    deleted_count: &mut usize,
) -> Result<(), String> {
    use crate::db::get_db_pool_sync;
    use rusqlite::params;
    
    let pool = get_db_pool_sync().map_err(|e| format!("è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: {}", e))?;
    let conn = pool.get().map_err(|e| format!("è·å–è¿æ¥å¤±è´¥: {}", e))?;
    
    // è·å–æ‰€æœ‰æœ‰ file_path çš„æ–‡ç« 
    let mut stmt = conn.prepare("SELECT id, file_path FROM passages WHERE file_path IS NOT NULL")
        .map_err(|e| format!("æŸ¥è¯¢å¤±è´¥: {}", e))?;
    
    let passage_rows = stmt.query_map([], |row| {
        Ok((
            row.get::<_, i64>(0)?,
            row.get::<_, Option<String>>(1)?,
        ))
    }).map_err(|e| format!("æŸ¥è¯¢å¤±è´¥: {}", e))?;
    
    for row in passage_rows {
        if let Ok((id, file_path)) = row {
            if let Some(fp) = file_path {
                let full_path = Path::new(&fp);
                if !full_path.exists() {
                    conn.execute("DELETE FROM passages WHERE id = ?", params![id])
                        .map_err(|e| format!("åˆ é™¤å¤±è´¥: {}", e))?;
                    *deleted_count += 1;
                    println!("ğŸ—‘ï¸  å·²åˆ é™¤ä¸å­˜åœ¨çš„æ–‡ç« è®°å½•: {}", fp);
                }
            }
        }
    }
    
    Ok(())
}

/// å°† Markdown è½¬æ¢ä¸º HTML
fn convert_markdown_to_html(markdown: &str) -> String {
    use pulldown_cmark::{Parser, html};
    
    let parser = Parser::new(markdown);
    let mut html_output = String::new();
    html::push_html(&mut html_output, parser);
    
    html_output
}